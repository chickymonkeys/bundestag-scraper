{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "\n",
    "import os, requests, urllib, zipfile, shutil, stat, re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime as date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility strings and flags\n",
    "\n",
    "# strings with data directory path\n",
    "XML_PATH  = './data/xml/'\n",
    "TXT_PATH  = './data/txt/'\n",
    "JSON_PATH = './data/json/'\n",
    "\n",
    "# flag to clear folders\n",
    "REFRESH_RAW_DATA = 1\n",
    "\n",
    "# root domain of German parliament website\n",
    "root = 'https://www.bundestag.de'\n",
    "# ajax request url\n",
    "asin = '/ajax/filterlist/de/services/opendata/488214-488214?limit=10&noFilterSet=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions to clean a directory\n",
    "\n",
    "def _remove_readonly(fn, path_, excinfo):\n",
    "    # Handle read-only files and directories\n",
    "    if fn is os.rmdir:\n",
    "        os.chmod(path_, stat.S_IWRITE)\n",
    "        os.rmdir(path_)\n",
    "    elif fn is os.remove:\n",
    "        os.lchmod(path_, stat.S_IWRITE)\n",
    "        os.remove(path_)\n",
    "\n",
    "def force_remove_file_or_symlink(path_):\n",
    "    try:\n",
    "        os.remove(path_)\n",
    "    except OSError:\n",
    "        os.lchmod(path_, stat.S_IWRITE)\n",
    "        os.remove(path_)\n",
    "\n",
    "def is_regular_dir(path_):\n",
    "    try:\n",
    "        mode = os.lstat(path_).st_mode\n",
    "    except os.error:\n",
    "        mode = 0\n",
    "    return stat.S_ISDIR(mode)\n",
    "\n",
    "def clear_dir(path_):\n",
    "    if is_regular_dir(path_):\n",
    "        # Given path is a directory, clear its content\n",
    "        for filename in os.listdir(path_):\n",
    "            pathname = os.path.join(path_, filename)\n",
    "            if is_regular_dir(pathname):\n",
    "                shutil.rmtree(pathname, onerror=_remove_readonly)\n",
    "            else:\n",
    "                force_remove_file_or_symlink(pathname)\n",
    "    else:\n",
    "        # Given path is a file or a symlink.\n",
    "        # Raise an exception here to avoid accidentally clearing the content\n",
    "        # of a symbolic linked directory.\n",
    "        raise OSError(\"Cannot call clear_dir() on a symbolic link\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_RAW_DATA:\n",
    "    for dir in [XML_PATH, TXT_PATH]:\n",
    "        # clear directories first\n",
    "        if os.listdir(dir):\n",
    "            clear_dir(dir)\n",
    "            print('%s cleared. Continue.' % dir)\n",
    "        else:    \n",
    "            print('%s is already empty. Continue.' % dir)\n",
    "\n",
    "    # HTTP request\n",
    "    page = requests.get(root + asin)\n",
    "    # assign BeautifulSoup object on response content\n",
    "    soup = bs(page.content)\n",
    "\n",
    "    # loop all anchor with this class\n",
    "    for a in soup.find_all(attrs={'class':'bt-link-dokument'}):\n",
    "        # retrieve plenary zip file from hrefs\n",
    "        zipcall, _ = urllib.request.urlretrieve(root + a['href'])\n",
    "        # extract all xml files of this legislature into raw folder\n",
    "        with zipfile.ZipFile(zipcall, \"r\") as f:\n",
    "            f.extractall(XML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all the .xml files in the folder\n",
    "for file in os.listdir(os.fsencode(XML_PATH)):\n",
    "\n",
    "    # decode the name of file\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    # work on just .xmls and remove everything else\n",
    "    if filename.endswith('.xml'):\n",
    "\n",
    "        # element tree XML parsing : get root\n",
    "        root = ET.parse(XML_PATH + filename).getroot()\n",
    "\n",
    "        # TEXT tag first to acquire the plenary body and split into lines\n",
    "        for child in root.iter('TEXT'):\n",
    "            # pre-processing document headers\n",
    "            body = re.sub(r'^(.*Deutscher Bundestag )([^-$]|[^\\u2014$]).*$|^\\([A-Z]{1}\\).*$', '', child.text, 0, re.M)\n",
    "            # insert a pattern for double new-lines\n",
    "            body = re.sub(r'((?<!\\n)\\n{2}(?!\\n))', 'LLLLL', body, 0, re.M)\n",
    "            # de-hyphen and wrap paragraphs\n",
    "            body = re.sub(r'(^.*[^-]{1})([-]{1}$|)(\\n)', r'\\1', body, 0, re.M)\n",
    "            # substitute pattern with double new-lines\n",
    "            body = re.sub(r'(LLLLL)', r'\\n\\n', body, 0, re.M)\n",
    "            # substitute more than three new lines with whitespace\n",
    "            # probably it is the page header removed before\n",
    "            body = re.sub(r'(\\n{3,})', ' ', body, 0, re.M)\n",
    "\n",
    "        # DATUM as the date of the plenary for file renaming\n",
    "        for child in root.iter('DATUM'):\n",
    "            plenaryDate = date.strptime(child.text, '%d.%m.%Y').strftime('%Y-%m-%d')\n",
    "            with open(TXT_PATH + plenaryDate + '.txt', 'w') as textfile:\n",
    "                textfile.write(body)\n",
    "                \n",
    "    else: \n",
    "        os.remove(XML_PATH + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done with the .txt. files\n",
    "# Now we start to with a single file and sort the JSON out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}